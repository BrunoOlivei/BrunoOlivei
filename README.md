<!-- Hero curto, claro e orientado a valor -->
# Bruno Oliveira — Data Engineer (Azure • Databricks • Spark)

Crio pipelines **ETL/ELT end-to-end** no Azure Data Factory + Databricks, estruturando **Lakehouse (Bronze/Silver/Gold)** com governança, qualidade e auditoria — sempre orientado a impacto de negócio.

- 🔭 Atual: automatizando ingestões em lote/stream para data lakehouse (Unity Catalog), versionando esquemas e PR-based deploy; automação de cálculos críticos (remuneração, cancelamentos, conciliações) em PySpark/SQL; monitoração e qualidade para evitar recorrência de erros.
- 🎯 Interesses: Lakehouse, Orquestração (ADF/Airflow), PySpark, Data Modeling, RAG para dados tabulares, custo/finops em Spark.
- 🧱 Stack: Databricks, PySpark/SQL, Delta Lake, ADF, Power BI, GitHub Actions, Docker, Airflow (básico).
- 📍 Brasil · 🌐 PT/EN · 💼 Aberto a remoto/híbrido.


**📄 Currículo:**  
- 👀 [Visualizar no GitHub (PDF, modo seguro)](https://github.com/BrunoOlivei/BrunoOlivei/blob/main/Curr%C3%ADculo_Bruno_Oliveira.pdf)
- ⬇️ [Baixar a versão mais recente (Release)](https://github.com/BrunoOlivei/BrunoOlivei/releases/latest/download/Curriculo.Bruno.Oliveira.pdf)  
- [LinkedIn](https://www.linkedin.com/in/BrunoOlivei)

---

## ⚡ Projetos em Destaque
- **Lakehouse Seguros (Demo com dados sintéticos)** — *ADF + Databricks + Delta + Unity Catalog*  
  Ingestão Bronze → curadoria Silver → métricas Gold; particionamento, schema evolution, SCD, e checkpoints de qualidade.  
  `azure-data-factory` `databricks` `pyspark` `delta-lake` `unity-catalog`

- **Orquestração de ETL com Airflow (Docker)** — *ELT incremental + testes de dados*  
  DAGs com backfills, SLA, retries, logs centralizados e Great Expectations.

- **Churn Modeling (ML Ops leve)** — *feature store simplificada + tracking*  
  Pipeline de features em Spark, treino com MLflow e serving via FastAPI.

---

## 🧰 Stack e práticas
**Linguagens/Compute:** Python, PySpark, SQL • **Orquestração:** ADF, Airflow  
**Lakehouse/Storage:** Databricks, Delta Lake, Unity Catalog, ADLS  
**Qualidade/Observabilidade:** Great Expectations, checks de schema, logging  
**Dev/CI:** GitHub Actions, testes, padrões de branch e PR com evidências

---

## 📚 Conteúdo e Notas
- Cheatsheets de PySpark/ADF, padrões de nomenclatura, templates de README.
- Estudos: modelagem de dados e particionamento para custos em Spark.

---
## Contato
- 📧 [Email](brunoolivei@protonmail.com)
- 💬 Abra uma *issue* em qualquer repo, ou fale pelo [LinkedIn](https://www.linkedin.com/in/BrunoOlivei).
